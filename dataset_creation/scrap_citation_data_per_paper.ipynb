{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d983897-8a92-4bc6-80e7-4128dd6b299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"dataset.sqlite3\")\n",
    "df = pd.read_sql_query(\"SELECT * from publications\", con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "print(df.head())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd37e94-0592-4fbf-a84f-c9a89fb5665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = df[(df['is_processed']==0) & (df['failed_attempt']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0797e-d848-4a04-88b8-5b1d2c2222b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_rows = df[df['failed_attempt']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effc747-13b7-4b86-8991-39e0ae57748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_but_processed_rows = df[(df['is_processed']==1) & (df['failed_attempt']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047171df-c513-4f76-a9dd-34d82a59e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8a9f0-f5ee-420a-8146-6c2a42ef0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d5393-947f-4b24-94a0-28dd493dd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbec2f4-c41a-4112-a08e-dcc4a2463c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f2816-7a94-450e-a2dd-6e080e041a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Define Chrome options for Selenium\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--headless=new')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36')\n",
    "\n",
    "def get_pub_details(work_url):\n",
    "    retry_attempts = 3\n",
    "\n",
    "    for attempt in range(retry_attempts):\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        try:\n",
    "            # print(f\"Attempting to access URL: {work_url}, Attempt: {attempt + 1}\")\n",
    "            error = 0\n",
    "            driver.get(work_url)\n",
    "            # Check if redirected to the human verification page\n",
    "            current_url = driver.current_url\n",
    "            if \"https://www.google.com/sorry/index\" in current_url:\n",
    "                print(f\"Blocked by Google at URL: {current_url}\")\n",
    "                print(\"Please change your IP and restart the script.\")\n",
    "                \n",
    "                # Option 1: Raise an exception\n",
    "                print(\"Blocked by Google. Change your IP and restart.\")\n",
    "        \n",
    "                # Option 2: Exit the script\n",
    "                sys.exit(\"Blocked by Google. Change your IP and restart.\")\n",
    "                \n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            # print(soup)\n",
    "            # print(soup.find('div', id='gsc_oci_title'))\n",
    "\n",
    "            # Extract title\n",
    "            try:\n",
    "                title_element = soup.find('div', id='gsc_oci_title')\n",
    "                title = title_element.text\n",
    "            except Exception as e:\n",
    "                title = None\n",
    "                error = 1\n",
    "            \n",
    "            # Extract authors or inventors\n",
    "            try:\n",
    "                try:\n",
    "                    author_field = soup.find('div', class_='gsc_oci_field', string='Authors')\n",
    "                    author_element = author_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "                    authors = author_element.text\n",
    "                except Exception as e:\n",
    "                    author_field = soup.find('div', class_='gsc_oci_field', string='Inventors')\n",
    "                    author_element = author_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "                    authors = author_element.text\n",
    "            except Exception as e:\n",
    "                authors = None\n",
    "\n",
    "            # Extract publication date\n",
    "            try:\n",
    "                published_date_field = soup.find('div', class_='gsc_oci_field', string='Publication date')\n",
    "                publication_date_element = published_date_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "                publication_date = publication_date_element.text\n",
    "            except Exception:\n",
    "                publication_date = None\n",
    "\n",
    "            # Extract type\n",
    "            try:\n",
    "                work_type_elem = soup.select_one(\"#gsc_oci_table > div:nth-child(3) > div:nth-child(1)\")\n",
    "                typ = work_type_elem.text\n",
    "            except Exception as e:\n",
    "                typ = None\n",
    "\n",
    "            # Extract citation count\n",
    "            try:\n",
    "                citation_field = soup.find('div', class_='gsc_oci_field', string='Total citations')\n",
    "                citation_field_element = citation_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "                citation_value = citation_field_element.find('div')\n",
    "                citation_count = int(re.search(r'\\d+', citation_value.get_text()).group())\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                citation_count = 0\n",
    "            # print(error)\n",
    "            # If successful, return the extracted data\n",
    "            return {\n",
    "                'error': error,\n",
    "                'publication_url': work_url,\n",
    "                'title': title,\n",
    "                'authors': authors,\n",
    "                'publication_date': publication_date,\n",
    "                'publication_type': typ,\n",
    "                'citations': citation_count,\n",
    "                'details_added_at': time.time()\n",
    "            }\n",
    "        \n",
    "        except TimeoutException:\n",
    "            error=1\n",
    "            print(f\"Timeout while trying to access {work_url}. Retrying...\")\n",
    "            time.sleep(5)  # Delay before retrying\n",
    "        except WebDriverException as e:\n",
    "            print(f\"WebDriver error while accessing {work_url}: {str(e)}\")\n",
    "            error = 1\n",
    "            if \"ERR_INTERNET_DISCONNECTED\" in str(e):\n",
    "                print(\"Internet disconnected. Stopping the program.\")\n",
    "                sys.exit(1)\n",
    "            break  # Stop retrying if WebDriver error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error occurred: {str(e)}\")\n",
    "            error = 1\n",
    "            break\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    # If all retries fail, return failure\n",
    "    print(f\"Failed to retrieve details for {work_url} after {retry_attempts} attempts.\")\n",
    "    return {\n",
    "        'error': 1,\n",
    "        'publication_url': work_url,\n",
    "        'title': None,\n",
    "        'authors': None,\n",
    "        'publication_date': None,\n",
    "        'publication_type': None,\n",
    "        'citations': 0,\n",
    "        'details_added_at': time.time()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5c928-9f52-4728-b3d4-dad7e9767645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "# from bs4 import BeautifulSoup\n",
    "# import time\n",
    "# import re\n",
    "\n",
    "# # Define Chrome options for Selenium\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument('--no-sandbox')\n",
    "# chrome_options.add_argument('--headless=new')\n",
    "# chrome_options.add_argument('--disable-gpu')\n",
    "# chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "# chrome_options.add_argument('--window-size=1920,1080')\n",
    "# chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36')\n",
    "\n",
    "# def get_pub_details(work_url):\n",
    "#     error=0\n",
    "#     driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "#     driver.get(work_url)\n",
    "#     page_source = driver.page_source\n",
    "#     soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "#     try:\n",
    "#         title_element = soup.find('div', id='gsc_oci_title')\n",
    "#         title = title_element.text\n",
    "#     except Exception as e:\n",
    "#         title = None\n",
    "#         error = 1\n",
    "\n",
    "#     try:\n",
    "#         try:\n",
    "#             author_field = soup.find('div', class_='gsc_oci_field', string='Authors')\n",
    "#             author_element = author_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "#             authors = author_element.text\n",
    "#         except Exception as e:\n",
    "#             author_field = soup.find('div', class_='gsc_oci_field', string='Inventors')\n",
    "#             author_element = author_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "#             authors = author_element.text\n",
    "#     except Exception as e:\n",
    "#         authors = None\n",
    "\n",
    "#     try:\n",
    "#         published_date_field = soup.find('div', class_='gsc_oci_field', string='Publication date')\n",
    "#         publication_date_element = published_date_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "#         publication_date = publication_date_element.text\n",
    "#     except Exception as e:\n",
    "#         publication_date = None\n",
    "\n",
    "#     try:\n",
    "#         work_type_elem = soup.select_one(\"#gsc_oci_table > div:nth-child(3) > div:nth-child(1)\")\n",
    "#         typ = work_type_elem.text\n",
    "#     except Exception as e:\n",
    "#         typ = None\n",
    "\n",
    "#     try:\n",
    "#         citation_field = soup.find('div', class_='gsc_oci_field', string='Total citations')\n",
    "#         citation_field_element = citation_field.find_next_sibling('div', class_='gsc_oci_value')\n",
    "#         citation_value = citation_field_element.find('div')\n",
    "#         citation_count = int(re.search(r'\\d+', citation_value.get_text()).group())\n",
    "#     except Exception as e:\n",
    "#         # print(str(e))\n",
    "#         citation_count = 0\n",
    "#     time.sleep(1.5)\n",
    "#     driver.quit()\n",
    "#     if error ==1:\n",
    "#         print(driver.current_url)\n",
    "    \n",
    "        \n",
    "#     # print({\n",
    "#     #     'error': error,\n",
    "#     #     'link': work_url,\n",
    "#     #     'title': title,\n",
    "#     #     'authors': authors,\n",
    "#     #     'publication_date': publication_date,\n",
    "#     #     'type': typ,\n",
    "#     #     'citation': citation_count\n",
    "#     # })\n",
    "#     return {\n",
    "#         'error': error,\n",
    "#         'publication_url': work_url,\n",
    "#         'title': title,\n",
    "#         'authors': authors,\n",
    "#         'publication_date': publication_date,\n",
    "#         'publication_type': typ,\n",
    "#         'citations': citation_count,\n",
    "#         'details_added_at': time.time()\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44904e10-dbb2-41bf-bddf-5d3d4e53f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database (replace 'your_database.db' with your database file name)\n",
    "conn = sqlite3.connect(\"dataset.sqlite3\")\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in selected_rows.iterrows():\n",
    "    # print(row['publication_url'])\n",
    "    details = get_pub_details(row['publication_url'])\n",
    "    # print(details)\n",
    "    if details['error']==0:\n",
    "        cursor.execute(\"UPDATE publications SET title = :title, author_names = :authors ,publication_date= :publication_date, publication_type= :publication_type , citations= :citations,is_processed=1,failed_attempt = 0, details_added_at= :details_added_at WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    else:\n",
    "        cursor.execute(\"UPDATE publications SET failed_attempt = 1 WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "print('code finished')\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ac2b3-8d03-4e4e-ba5d-aa5a4c4ff897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####retrying failed attempts######################\n",
    "\n",
    "# Connect to the SQLite database (replace 'your_database.db' with your database file name)\n",
    "conn = sqlite3.connect(\"dataset.sqlite3\")\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in failed_rows.iterrows():\n",
    "    # print(row['publication_url'])\n",
    "    details = get_pub_details(row['publication_url'])\n",
    "    # print(details)\n",
    "    if details['error']==0:\n",
    "        cursor.execute(\"UPDATE publications SET title = :title, author_names = :authors ,publication_date= :publication_date, publication_type= :publication_type , citations= :citations,is_processed=1,failed_attempt = 0, details_added_at= :details_added_at WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    else:\n",
    "        cursor.execute(\"UPDATE publications SET failed_attempt = 1 WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "print('code finished')\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63264f03-1352-4f3b-b582-4c227854b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####retrying failed but processed rows attempts######################\n",
    "\n",
    "# Connect to the SQLite database (replace 'your_database.db' with your database file name)\n",
    "conn = sqlite3.connect(\"dataset.sqlite3\")\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in failed_but_processed_rows.iterrows():\n",
    "    # print(row['publication_url'])\n",
    "    details = get_pub_details(row['publication_url'])\n",
    "    print(details)\n",
    "    if details['error']==0:\n",
    "        cursor.execute(\"UPDATE publications SET title = :title, author_names = :authors ,publication_date= :publication_date, publication_type= :publication_type , citations= :citations,is_processed=1,failed_attempt = 0, details_added_at= :details_added_at WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    else:\n",
    "        cursor.execute(\"UPDATE publications SET failed_attempt = 1 WHERE publication_url = :publication_url\", details)\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "print('code finished')\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217690a-0cd0-4894-837e-001a7b52e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_pub_details('https://scholar.google.com/citations?view_op=view_citation&hl=en&user=jtDUXJkAAAAJ&pagesize=100&citation_for_view=jtDUXJkAAAAJ:dhFuZR0502QC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085902a-7797-4d0a-ae7a-ca9adf2084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pub_details('https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vo8WTYAAAAJ&pagesize=100&citation_for_view=3vo8WTYAAAAJ:CLhUwle04lcC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72ec1a-88d9-472c-aa65-c462e8ca302d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
