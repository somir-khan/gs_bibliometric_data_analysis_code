{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce7dba-2094-4bb2-9ef3-20f64e587c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322c341-92de-489d-9438-54d175d5456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "# General options\n",
    "chrome_options.add_argument('--no-sandbox')  # Required for certain environments\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')  # Address shared memory issue\n",
    "chrome_options.add_argument(\"--disable-extensions\")  # Disable extensions to appear more like a normal browser\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Bypass automation detection\n",
    "\n",
    "# Mimic a user-like behavior\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Start the browser maximized\n",
    "chrome_options.add_argument('--disable-infobars')  # Disable the 'Chrome is being controlled by automation' bar\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")  # Set window size\n",
    "chrome_options.add_argument(\"--enable-javascript\")  # Ensure JavaScript is enabled\n",
    "chrome_options.add_argument(\"--incognito\")  # Use incognito mode\n",
    "\n",
    "# User-Agent modification\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Prevent detection\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# Optional headless mode (Comment this out if you want to see the browser UI)\n",
    "chrome_options.add_argument('--headless')  # Run without GUI\n",
    "chrome_options.add_argument('--disable-gpu')  # Necessary in headless mode for some systems\n",
    "\n",
    "# Handle proxy and languages if needed\n",
    "chrome_options.add_argument(\"--lang=en-US\")  # Set browser language\n",
    "chrome_options.add_argument('--proxy-server=\"direct://\"')  # Disable proxy\n",
    "chrome_options.add_argument('--proxy-bypass-list=*')  # Bypass all proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449972ea-3fe0-4d1e-a271-67147cba1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"dataset.sqlite3\")\n",
    "df = pd.read_sql_query(\"SELECT sub_field FROM authors\", con)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fb1b8-8a51-4ecf-a3ce-36fc0a406e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d0104-04a0-4881-8f0d-36cb0a2a66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_author_data(authors):\n",
    "    con = sqlite3.connect(\"/home/somir/Desktop/CitationDataset/dataset.sqlite3\")\n",
    "    c = con.cursor()\n",
    "    \n",
    "    for author in authors:\n",
    "        try:\n",
    "            con.execute(\"\"\"\n",
    "    INSERT INTO\n",
    "        authors\n",
    "        (scholar_id, name, profile_link, field, sub_field,research_areas, page_number, page_rank, page_url,created_at)\n",
    "    VALUES\n",
    "        (:scholar_id, :author_name, :profile_link, :field, :sub_field, :research_areas, :page_number, :page_rank, :page_url, :created_at)\"\"\", author)\n",
    "        except Exception as error:\n",
    "            print(str(error))\n",
    "            print(\"An exception occurred:\", type(error).__name__)\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee9714-beaa-4196-b709-55e448c1eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_authors(field_label: str, sub_field_label: str, total_pages=200):\n",
    "    if sub_field_label in df['sub_field'].values:\n",
    "        return \"Already Done\"\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    url = 'http://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:' + sub_field_label\n",
    "    driver.get(url)\n",
    "    print(driver.current_url)\n",
    "    author_list = []\n",
    "    # get competition \"All competition\" button\n",
    "    for i in range(0, total_pages):\n",
    "        elems = driver.find_elements(By.CLASS_NAME, \"gsc_1usr\")\n",
    "        rank = random.randint(1, len(elems))\n",
    "        elem = elems[rank - 1]\n",
    "        name = elem.find_element(By.CLASS_NAME, \"gs_ai_name\")\n",
    "        url = name.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "        parsed_url = urlparse(url)\n",
    "        scholar_id = parse_qs(parsed_url.query)['user'][0]\n",
    "        page_url = driver.current_url\n",
    "\n",
    "        # Extract research areas\n",
    "        html_content = elem.get_attribute('innerHTML')  # Get the inner HTML of the element\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        research_areas = [a.text for a in soup.find_all('a', class_='gs_ai_one_int')]  # Extract research area labels\n",
    "        research_areas_text = \", \".join(research_areas)\n",
    "\n",
    "        dic = {\n",
    "            'field': field_label,\n",
    "            'sub_field': sub_field_label,\n",
    "            'scholar_id': scholar_id,\n",
    "            'author_name': name.text,\n",
    "            'page_number': i + 1,\n",
    "            'page_url': page_url,\n",
    "            'page_rank': rank,\n",
    "            'profile_link': url,\n",
    "            'research_areas': research_areas_text,  # Add research areas to the dictionary\n",
    "            'created_at': time.time()\n",
    "        }\n",
    "        author_list.append(dic)\n",
    "        # print(dic)\n",
    "        # break\n",
    "\n",
    "        # Selecting the next button to load next page\n",
    "        elem = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Next\"]')\n",
    "        is_disabled = elem.get_attribute(\"disabled\")\n",
    "        if is_disabled:\n",
    "            break\n",
    "        else:\n",
    "            elem.click()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            ul = driver.current_url\n",
    "            driver.quit()\n",
    "            driver = webdriver.Chrome(options=chrome_options)\n",
    "            driver.get(ul)\n",
    "        time.sleep(5)\n",
    "    \n",
    "    save_author_data(author_list)\n",
    "    return \"Saved \" + field_label + \"-\" + sub_field_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75485c45-92d6-479a-aa89-49c82b1db9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from random import sample \n",
    "\n",
    "def get_authors_custom(field_label: str, sub_field_label: str, total_pages=200,selection_number=1):\n",
    "    if sub_field_label in df['sub_field'].values:\n",
    "        return \"Already Done\"\n",
    "    expected_value_calculation = {\n",
    "    'economic_sociology': {'threshold': 53, 'param1': 2, 'param2': 3},\n",
    "    'brand_management': {'threshold': 43, 'param1': 2, 'param2': 3},\n",
    "    'marketing_strategy': {'threshold': 30, 'param1': 2, 'param2': 3},\n",
    "    'microelectronics': {'threshold': 83, 'param1': 1, 'param2': 2},\n",
    "    'microeconomics': {'threshold': 60, 'param1': 1, 'param2': 2},\n",
    "    'algebra': {'threshold': 67, 'param1': 1, 'param2': 2},\n",
    "    'number_theory': {'threshold': 40, 'param1': 1, 'param2': 2},\n",
    "    'combinatorics': {'threshold': 67, 'param1': 1, 'param2': 2}\n",
    "}\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    url = 'http://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:' + sub_field_label\n",
    "    driver.get(url)\n",
    "    print(driver.current_url)\n",
    "    author_list = []\n",
    "    # get competition \"All competition\" button\n",
    "    for i in range(0, total_pages):\n",
    "        elems = driver.find_elements(By.CLASS_NAME, \"gsc_1usr\")\n",
    "\n",
    "        if sub_field_label in expected_value_calculation:\n",
    "            params = expected_value_calculation[sub_field_label]\n",
    "            selection_number = random_decision(**params)\n",
    "    \n",
    "        # Ensure there are at least two profiles on the page\n",
    "        if len(elems) < selection_number:\n",
    "            print(\"Not enough profiles on this page to select.\")\n",
    "            continue\n",
    "\n",
    "        # Randomly select two unique indices\n",
    "        selected_indices = sample(range(len(elems)), selection_number)  # Get unique random indices\n",
    "\n",
    "        for rank in selected_indices:\n",
    "            elem = elems[rank]  # Select the profile element\n",
    "            name = elem.find_element(By.CLASS_NAME, \"gs_ai_name\")\n",
    "            url = name.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            parsed_url = urlparse(url)\n",
    "            scholar_id = parse_qs(parsed_url.query)['user'][0]\n",
    "            page_url = driver.current_url\n",
    "    \n",
    "            # Extract research areas\n",
    "            html_content = elem.get_attribute('innerHTML')  # Get the inner HTML of the element\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            research_areas = [a.text for a in soup.find_all('a', class_='gs_ai_one_int')]  # Extract research area labels\n",
    "            research_areas_text = \", \".join(research_areas)\n",
    "            \n",
    "            # Print or store the data for each profile\n",
    "            # print(f\"Name: {name.text}\")\n",
    "            # print(f\"Profile URL: {url}\")\n",
    "            # print(f\"Scholar ID: {scholar_id}\")\n",
    "            # print(f\"Research Areas: {research_areas_text}\")\n",
    "            # print(f\"Page URL: {page_url}\")\n",
    "            # print(\"-\" * 50)\n",
    "\n",
    "            dic = {\n",
    "                'field': field_label,\n",
    "                'sub_field': sub_field_label,\n",
    "                'scholar_id': scholar_id,\n",
    "                'author_name': name.text,\n",
    "                'page_number': i + 1,\n",
    "                'page_url': page_url,\n",
    "                'page_rank': rank,\n",
    "                'profile_link': url,\n",
    "                'research_areas': research_areas_text,  # Add research areas to the dictionary\n",
    "                'created_at': time.time()\n",
    "            }\n",
    "            author_list.append(dic)\n",
    "        # print(dic)\n",
    "\n",
    "        # Selecting the next button to load next page\n",
    "        elem = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Next\"]')\n",
    "        is_disabled = elem.get_attribute(\"disabled\")\n",
    "        if is_disabled:\n",
    "            break\n",
    "        else:\n",
    "            elem.click()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            ul = driver.current_url\n",
    "            # driver.quit()\n",
    "            # driver = webdriver.Chrome(options=chrome_options)\n",
    "            # driver.get(ul)\n",
    "    \n",
    "    save_author_data(author_list)\n",
    "    return \"Saved \" + field_label + \"-\" + sub_field_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be678b2-f951-4789-b467-1593cf950551",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'computer_science': ['software_engineering', 'cyber_security', 'computer_networks'],\n",
    "    'biology': ['genetics', 'microbiology', 'molecular_biology'],\n",
    "    'electrical_engineering': ['signal_processing', 'microelectronics','power_electronics'],\n",
    "    'civil_engineering': ['environmental_engineering', 'geotechnical_engineering', 'structural_engineering'],\n",
    "    'psychology': ['cognitive_psychology', 'developmental_psychology', 'social_psychology'],\n",
    "    'sociology': ['demography', 'criminology', 'economic_sociology'],\n",
    "    'marketing': ['consumer_behavior', 'brand_management', 'marketing_strategy'],\n",
    "    'economics': ['econometrics', 'microeconomics', 'macroeconomics'],\n",
    "    'mathematics':['algebra','combinatorics','number_theory']\n",
    "}\n",
    "for field, subfields in keywords.items():\n",
    "    # Loop through the list of subfields/topics for each key\n",
    "    for subfield in subfields:\n",
    "        print(get_authors_custom(field, subfield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e58105-adf2-45c7-bda5-4178b345413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_decision(threshold,param1,param2):\n",
    "    \"\"\"\n",
    "    Generates a random number between 0 and 100.\n",
    "    Returns 1 if the number is greater than the threshold, otherwise returns 2.\n",
    "\n",
    "    Args:\n",
    "        threshold (int): The threshold value to compare against (0 to 100).\n",
    "\n",
    "    Returns:\n",
    "        int: 1 if random number > threshold, otherwise 2.\n",
    "    \"\"\"\n",
    "    if not 0 <= threshold <= 100:\n",
    "        raise ValueError(\"Threshold must be between 0 and 100.\")\n",
    "    \n",
    "    random_number = random.randint(0, 100)\n",
    "    # print(f\"Generated Random Number: {random_number}\")\n",
    "    \n",
    "    if random_number > threshold:\n",
    "        return param2\n",
    "    else:\n",
    "        return param1\n",
    "\n",
    "# Example usage\n",
    "# threshold = 50  # You can set this to any value between 0 and 100\n",
    "result = random_decision(50,1,2)\n",
    "print(f\"Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5db74-58ab-4ce1-b1da-0903f8d99164",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'electrical_engineering': ['microelectronics'],\n",
    "    'sociology': ['economic_sociology'],\n",
    "    'marketing': ['brand_management', 'marketing_strategy'],\n",
    "    'economics': ['microeconomics'],\n",
    "}\n",
    "\n",
    "for field, subfields in keywords.items():\n",
    "    # Loop through the list of subfields/topics for each key\n",
    "    for subfield in subfields:\n",
    "        print(get_authors_custom(field, subfield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d923f3a-3bf4-414b-b052-f4bea57abe85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
